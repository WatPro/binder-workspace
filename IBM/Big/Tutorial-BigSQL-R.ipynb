{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Working with Hadoop data using SQL (with R)\n",
    "\n",
    "In this tutorial you will learn to work data in Hadoop using SQL. \n",
    "\n",
    "If you specialize in relational database management technology and you have to deal with big data, Apache Hadoop is a perfect container to store and manupulate your data. To query the data stored in Hadoop, we need [__Big SQL__](http://www-01.ibm.com/software/data/infosphere/hadoop/big-sql.html). It allows you to query data stored in Hadoop using industry-standard SQL syntax. Big SQL is designed to provide SQL developers with an easy on-ramp for querying data managed by Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Big SQL?\n",
    "[IBM Big SQL](http://www-01.ibm.com/software/data/infosphere/hadoop/big-sql.html) provides standards-compliant SQL access to data in Hadoop. Developers familiar with SQL can access data in Hadoop without having to learn new languages or skills.\n",
    "\n",
    "You can work with Hadoop data using SQL in a Jupyter Notebook. The required libraries are pre-installed in your Data Scientist Workbench, so you can establish a connection to a remote Hadoop cluster with Big SQL and then run SQL queries over data in Hadoop.\n",
    "\n",
    "First, we load the packages we need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install.packages(\"RJDBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(RJDBC);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the database for this tutorial, you need to get your own set of credentials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "Here are steps on how to get your username/password :\n",
    "\n",
    "1. Sign up for a free account on  [IBM Analytics Demo Cloud](https://my.imdemocloud.com/users/sign_up).\n",
    "\n",
    "2. An activation email will be sent to you. Please follow up the instructions to set up your account (Note: Your username is different from your email address. For example, the username for `jane.doe@example.com` might be `janedoe`. You can see your username in the top-right corner of Demo Cloud when you're logged in.).\n",
    "\n",
    "3. Log in [IBM Analytics Demo Cloud](https://my.imdemocloud.com/users/sign_up) and click __Big SQL Technology Sandbox project__ to join it. You will be automatically approved to join.\n",
    "\n",
    "4. Type in your **username** and **password** within the quotations in the code cell below.\n",
    "\n",
    "Click inside the cells below and run the cells (_Ctrl+Enter_) to set up a connection to the Big SQL Technology Preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = \"\";\n",
    "password = \"\"\n",
    "database = \"bigsql\";\n",
    "hostname = \"iop-bi-master.imdemocloud.com\";\n",
    "port = \"32051\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to run the cell below as well (_Ctrl+Enter_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jcc = JDBC(\"com.ibm.db2.jcc.DB2Driver\", \"/usr/local/lib/db2jcc4.jar\");\n",
    "jdbc_path = paste(\"jdbc:db2://\",  hostname, \":\", port, \"/\", database, sep=\"\");\n",
    "conn = dbConnect(jcc, jdbc_path, user=username, password=password)\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great! Now you're connected!**  \n",
    "_If you saw an error, check that you filled in your username and password correctly._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try using SQL queries on a sample table\n",
    "\n",
    "In this section, we will create a sample table, named __testTable__, load some data into it, and execute a query. Before we do this, we first want to check to see if the table already exists, and if it does, we remove it so we can start from scratch.\n",
    "\n",
    "\n",
    "To prepare and execute a single SQL statement, use the __dbSendUpdate()__ and __dbSendQuery()__ that submits a query to the database and synchronously executes the SQL statement. The difference between the two is only that _dbSendUpdate_ is used with DBML queries and thus doesnâ€™t return any result set.\n",
    "  \n",
    "__Note:__ In Big SQL, there is only one database, __bigsql__, and you cannot create a new database. However, you can have your own schema (which defaults to your user connection name). So, if you connect to the database using your name and execute \"CREATE HADOOP TABLE testTable\", it creates a table called _YOUR_USER_NAME.testTable_ under your schema. \n",
    "\n",
    "To make sure we are using our schema, we first execute the __USE__ query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = paste('USE ', username)\n",
    "dbSendUpdate(conn, query);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we drop the table if it already exists (so we can create a new one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query=\"DROP TABLE IF EXISTS testTable\"\n",
    "dbSendUpdate(conn, query);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a new table, __testTable__ with two columns, named __column1__ and __column2__. To create the table in your schema, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query=\"CREATE HADOOP TABLE testTable (column1 INT, column2 STRING)\"\n",
    "dbSendUpdate(conn, query);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets insert some data into our **testTable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query=\"INSERT INTO testTable VALUES (1,'Text1')\"\n",
    "dbSendUpdate(conn, query);\n",
    "query=\"INSERT INTO testTable VALUES (2,'Text2')\"\n",
    "dbSendUpdate(conn, query);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can we can retrieve the data as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM testTable\";\n",
    "rs = dbSendQuery(conn, query);\n",
    "df = fetch(rs, -1);\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Big Data Sample\n",
    "In this section we use sample data that is provided in BigSQL by default. We will use to run queries and create reports about the fictional __Sample Outdoor Company__. \n",
    "\n",
    "The schema that is used in this tutorial is the GOSALESDW. It contains fact tables for the following areas:\n",
    "\n",
    "* Distribution\n",
    "* Finance\n",
    "* Geography\n",
    "* Marketing\n",
    "* Organization\n",
    "* Personnel\n",
    "* Products\n",
    "* Retailers\n",
    "* Sales\n",
    "* Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"use GOSALESDW\";\n",
    "dbSendUpdate(conn, query);\n",
    "query = \"select * from EMP_EMPLOYEE_DIM LIMIT 5\";\n",
    "rs = dbSendQuery(conn, query);\n",
    "df = fetch(rs, -1);\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can improve the _SELECT *_ statement by adding a _predicate_ to the second statement to return fewer rows. A predicate is a condition on a query that reduces and narrows the focus of the result. A predicate on a query with a multi-way join can improve the performance of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM gosalesdw.go_region_dim WHERE region_en LIKE 'Amer%'\";\n",
    "rs = dbSendQuery(conn, query);\n",
    "df = fetch(rs, -1);\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run a query that returns the number of rows in a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT COUNT(*) FROM gosalesdw.go_region_dim\";\n",
    "rs = dbSendQuery(conn, query);\n",
    "df = fetch(rs, -1);\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn what products were ordered from the fictional Sample Outdoor Company, and by what method they were ordered, you must join information from multiple tables in the __gosalesdw__ database because it is a relational database where not everything is in one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query =\"\\\n",
    "SELECT pnumb.product_name, sales.quantity, \\\n",
    "  meth.order_method_en \\\n",
    "FROM \\\n",
    "  gosalesdw.sls_sales_fact sales, \\\n",
    "  gosalesdw.sls_product_dim prod, \\\n",
    "  gosalesdw.sls_product_lookup pnumb, \\\n",
    "  gosalesdw.sls_order_method_dim meth \\\n",
    "WHERE \\\n",
    "  pnumb.product_language='EN' \\\n",
    "  AND sales.product_key=prod.product_key \\\n",
    "  AND prod.product_number=pnumb.product_number \\\n",
    "  AND meth.order_method_key=sales.order_method_key\"\n",
    "rs = dbSendQuery(conn, query);\n",
    "df = fetch(rs, -1);\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbDisconnect(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference\n",
    "\n",
    "For more information on Big SQL, please visit the [Big SQL reference page](https://www-01.ibm.com/support/knowledgecenter/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.bigsql.doc/doc/bsql_reference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://bigdatauniversity.com/courses/sql-access-on-hadoop-big-sql-v4/?utm_source=bigsql-r&utm_medium=dswb&utm_campaign=bdu\"><img src = \"https://ibm.box.com/shared/static/s5ensv6192ntt3cnwqsmytvxsaunrlmv.png\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Authors:</h3>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAaTAAAAJDdlYjZkMjE5LTEyYzItNGVhNS04OGYxLTY2NjMwOGFmOWNhNg.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "<h4>Saeed Aghabozorgi</h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "</article>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone size-medium wp-image-2177\" src=\"https://media.licdn.com/mpr/mpr/shrinknp_400_400/p/7/005/08e/36c/0d2e309.jpg\" alt=\"Alan Barnes\" width=\"300\" height=\"300\" /></div>\n",
    "<h4>Polong Lin</h4>\n",
    "<p>\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">Polong Lin</a> is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds a M.Sc. in Cognitive Psychology.</p>\n",
    "</article>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).â€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
