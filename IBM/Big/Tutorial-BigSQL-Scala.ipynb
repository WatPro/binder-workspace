{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Working with Hadoop data using SQL (with Scala)\n",
    "\n",
    "In this tutorial you will learn to work data in Hadoop using SQL. \n",
    "\n",
    "If you specialize in relational database management technology and you have to deal with big data, Apache Hadoop is a perfect container to store and manupulate your data. To query the data stored in Hadoop, we need [__Big SQL__](http://www-01.ibm.com/software/data/infosphere/hadoop/big-sql.html). It allows you to query data stored in Hadoop using industry-standard SQL syntax. Big SQL is designed to provide SQL developers with an easy on-ramp for querying data managed by Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Big SQL?\n",
    "[IBM Big SQL](http://www-01.ibm.com/software/data/infosphere/hadoop/big-sql.html) provides standards-compliant SQL access to data in Hadoop. Developers familiar with SQL can access data in Hadoop without having to learn new languages or skills.\n",
    "\n",
    "You can work with Hadoop data using SQL in a Jupyter Notebook. The required libraries are pre-installed in your Data Scientist Workbench, so you can establish a connection to a remote Hadoop cluster with Big SQL and then run SQL queries over data in Hadoop.\n",
    "\n",
    "First, we load the packages we need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import java.sql.{Connection, DriverManager, ResultSet};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the database for this tutorial, you need to get your own set of credentials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "Here are steps on how to get your username/password :\n",
    "\n",
    "1. Sign up for a free account on  [IBM Analytics Demo Cloud](https://my.imdemocloud.com/users/sign_up).\n",
    "\n",
    "2. An activation email will be sent to you. Please follow up the instructions to set up your account (Note: Your username is different from your email address. For example, the username for `jane.doe@example.com` might be `janedoe`. You can see your username in the top-right corner of Demo Cloud when you're logged in.).\n",
    "\n",
    "3. Log in [IBM Analytics Demo Cloud](https://my.imdemocloud.com/users/sign_up) and click __Big SQL Technology Sandbox project__ to join it. You will be automatically approved to join.\n",
    "\n",
    "4. Type in your **username** and **password** within the quotations in the code cell below.\n",
    "\n",
    "Click inside the cells below and run the cells (_Ctrl+Enter_) to set up a connection to the Big SQL Technology Preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val username = \"\";\n",
    "val password = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scala code gets compiled into byte code that runs on a Java™ virtual machine (JVM), which allows Scala applications to directly call Java libraries. Therefore, accessing Big SQL from a Scala application is simply a matter of using the existing JDBC driver for DB2: the IBM Data Server Driver for JDBC and SQLJ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "java.sql.DriverManager.registerDriver(new com.ibm.db2.jcc.DB2Driver)\n",
    "val connection = java.sql.DriverManager.getConnection(\"jdbc:db2://iop-bi-master.imdemocloud.com:32051/bigsql\", username, password)\n",
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great! Now you're connected!**  \n",
    "_If you saw an error, check that you filled in your username and password correctly._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try using SQL queries on a sample table\n",
    "\n",
    "In this section, we will create a sample table, named __testTable__, load some data into it, and execute a query. Before we do this, we first want to check to see if the table already exists, and if it does, we remove it so we can start from scratch.\n",
    "\n",
    "To prepare and execute a single SQL statement, you use the __connection.createStatement.executeQuery()__ or __connection.createStatement.executeUpdate__ function. You can call this function and pass the following argument:\n",
    "* __statement__  \n",
    "  * A string that contains the SQL statement. This string can include an XQuery expression that is wrapped by an XMLQUERY clause.\n",
    "  \n",
    "__Notice:__ In Big SQL, there is only one database, __bigsql__, and you cannot create a new database. However, you CAN have your own schema (which defaults to your user connection name). So, if you connect to the database using your name and execute \"CREATE HADOOP TABLE testTable\", it creates a table called _YOUR_USER_NAME.testTable_ under your schema. \n",
    "\n",
    "To make sure we are using our schema, we first execute __USE__ query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query = \"USE \"+username;\n",
    "connection.createStatement.executeUpdate(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we drop the table if it already exists (so we can create a new one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query=\"DROP TABLE IF EXISTS testTable\"\n",
    "connection.createStatement.executeUpdate(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a new table, __testTable__ with two columns, named __column1__ and __column2__. To create the table in your schema, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query=\"CREATE HADOOP TABLE testTable (column1 INT, column2 STRING)\"\n",
    "connection.createStatement.executeUpdate(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets insert some data into our _testTable_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query=\"INSERT INTO testTable VALUES (1,'Text1') \"\n",
    "connection.createStatement.executeUpdate(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can we can retrieve the data as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query = \"SELECT * FROM testTable\";\n",
    "val resultSet = connection.createStatement.executeQuery(query)\n",
    "resultSet.next() \n",
    "println (\"The COLUMN1 value is : \"+ resultSet.getString(\"COLUMN1\"))\n",
    "println (\"The COLUMN2 value is : \"+ resultSet.getString(\"COLUMN2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Big Data Sample\n",
    "In this section we use sample data that is provided in BigSQL by default. We will use to run queries and create reports about the fictional __Sample Outdoor Company__. \n",
    "\n",
    "The schema that is used in this tutorial is the GOSALESDW. It contains fact tables for the following areas:\n",
    "\n",
    "* Distribution\n",
    "* Finance\n",
    "* Geography\n",
    "* Marketing\n",
    "* Organization\n",
    "* Personnel\n",
    "* Products\n",
    "* Retailers\n",
    "* Sales\n",
    "* Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query = \"select * from gosalesdw.emp_employee_dim LIMIT 10\";\n",
    "val resultSet = connection.createStatement.executeQuery(query)\n",
    "while ( resultSet.next() ) {\n",
    "    val name = resultSet.getString(\"EMPLOYEE_NAME\")\n",
    "    val key = resultSet.getString(\"EMPLOYEE_KEY\")\n",
    "    println(\"Employee key, name = \" + key + \", \" + name)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can improve the _SELECT *_ statement by adding a _predicate_ to the second statement to return fewer rows. A predicate is a condition on a query that reduces and narrows the focus of the result. A predicate on a query with a multi-way join can improve the performance of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query = \"SELECT * FROM gosalesdw.go_region_dim WHERE region_en LIKE 'Amer%'\";\n",
    "val resultSet = connection.createStatement.executeQuery(query)\n",
    "while ( resultSet.next() ) {\n",
    "    val REGION_CODE = resultSet.getString(\"REGION_CODE\")\n",
    "    println(\"REGION_CODE = \" + REGION_CODE )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run a query that returns the number of rows in a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query = \"SELECT COUNT(*) as con FROM gosalesdw.go_region_dim\";\n",
    "val resultSet = connection.createStatement.executeQuery(query)\n",
    "resultSet.next() \n",
    "println (\"The count is : \"+ resultSet.getString(\"con\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn what products were ordered from the fictional Sample Outdoor Company, and by what method they were ordered, you must join information from multiple tables in the __gosalesdw__ database because it is a relational database where not everything is in one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val query =\"\"\"\n",
    "SELECT \n",
    "  pnumb.product_name, \n",
    "  sales.quantity, \n",
    "  meth.order_method_en \n",
    "FROM gosalesdw.sls_sales_fact sales\n",
    "INNER JOIN gosalesdw.sls_product_dim prod\n",
    "  ON sales.product_key=prod.product_key \n",
    "INNER JOIN gosalesdw.sls_product_lookup pnumb\n",
    "  ON prod.product_number=pnumb.product_number \n",
    "INNER JOIN gosalesdw.sls_order_method_dim meth \n",
    "  ON meth.order_method_key=sales.order_method_key\n",
    "WHERE pnumb.product_language='EN'\n",
    "FETCH FIRST 10 ROWS ONLY\n",
    "\"\"\"\n",
    "val resultSet = connection.createStatement.executeQuery(query)\n",
    "while ( resultSet.next() ) {\n",
    "    val PRODUCT_NAME = resultSet.getString(\"PRODUCT_NAME\")\n",
    "    println(\"PRODUCT_NAME = \" + PRODUCT_NAME )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as a best practice we should close the database connection once we're done with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "For more information on Big SQL, please visit the [Big SQL reference page](https://www-01.ibm.com/support/knowledgecenter/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.bigsql.doc/doc/bsql_reference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://bigdatauniversity.com/courses/sql-access-on-hadoop-big-sql-v4/?utm_source=tutorial-bigsql-scala&utm_medium=dswb&utm_campaign=bdu\"><img src = \"https://ibm.box.com/shared/static/s5ensv6192ntt3cnwqsmytvxsaunrlmv.png\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Authors:</h3>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "<h4>Saeed Aghabozorgi</h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "</article>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone size-medium wp-image-2177\" src=\"https://ibm.box.com/shared/static/2ygdi03ahcr97df2ofrr6cf8knq4kodd.jpg\" alt=\"Polong Lin\" width=\"300\" height=\"300\" /></div>\n",
    "<h4>Polong Lin</h4>\n",
    "<p>\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">Polong Lin</a> is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds a M.Sc. in Cognitive Psychology.</p>\n",
    "</article>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10.4",
   "language": "scala",
   "name": "spark"
  },
  "language_info": {
   "name": "scala"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
