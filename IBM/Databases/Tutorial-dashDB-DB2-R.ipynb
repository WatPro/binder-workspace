{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - How to access dashDB data with SparkR\n",
    "Welcome to Cognitive Class Labs. This notebook is designed to teach you how to access data on dashDB using SparkR.\n",
    "\n",
    "This notebook shows how to access a dashDB Data Warehouse (or a DB2 database) using R by following the steps below:\n",
    "1. Loading the `RJDBC` Python library\n",
    "1. Identify and enter the database connection credentials\n",
    "1. Load the data from dashDB into a SparkR dataframe\n",
    "1. Query the data\n",
    "\n",
    "## What is dashDB ?\n",
    "\n",
    "**dashDB** is a fully managed cloud data warehouse, purpose-built for analytics. It offers massively parallel processing (MPP) scale, and compatibility with a wide range of business intelligence (BI) tools.  \n",
    "\n",
    "\n",
    "__Notice:__ Get your own dashDB free of charge: \n",
    "\n",
    "<h3 align = \"center\">\n",
    "[Launch a dashDB service through Bluemix](https://console.ng.bluemix.net/?direct=classic/&amp;cm_mc_uid=&amp;cm_mc_sid_50200000=1453781614#/store/cloudOEPaneId=store&amp;serviceOfferingGuid=7c87c148-e1a4-4cb8-81f8-c5e74be7684b&CampID=DSWB)\n",
    "</h3>\n",
    "\n",
    "<a class=\"ibm-tooltip\" href=\"https://console.ng.bluemix.net/?direct=classic/&amp;cm_mc_uid=&amp;cm_mc_sid_50200000=1453781614#/store/cloudOEPaneId=store&amp;serviceOfferingGuid=7c87c148-e1a4-4cb8-81f8-c5e74be7684b&CampID=DSWB\" target=\"_blank\" title=\"\" id=\"ibm-tooltip-0\">\n",
    "<img alt=\"IBM Bluemix.Get started now\" height=\"193\" width=\"153\" src=\"https://ibm.box.com/shared/static/42yt39czuksqdi278xpy96txtlw3lfmb.png\" >\n",
    "</a> \n",
    "\n",
    "## Load the `RJDBC` library. \n",
    "RJDBC is an implementation of R's DBI interface using JDBC as a back-end. This allows R to connect to any DBMS that has a JDBC driver.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(RJDBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Identify the database connection credentials\n",
    "\n",
    "Connecting to dashDB or DB2 database requires the following information:\n",
    "* Database name \n",
    "* Host DNS name or IP address \n",
    "* Host port\n",
    "* User ID\n",
    "* User Password\n",
    "\n",
    "All of this information must be captured in a connection string in a subsequent step.\n",
    "\n",
    "__Notice:__ To obtain credentials follow this [user guide](http://support.datascientistworkbench.com/knowledgebase/articles/826020-getting-credentials-to-access-a-dashdb-data-wareho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsn_username = \"<your username>\"  # e.g.  dash104434\n",
    "dsn_password = \"<your password>\"   # e.g. xxxx\n",
    "dsn_hostname = \"<your hostname>\"  # e.g.  awh-yp-small03.services.dal.bluemix.net\n",
    "dsn_port = \"<your port>\"   # e.g.  \"50000\"\n",
    "dsn_database = \"<default database>\"   # e.g BLUDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the database connection with SparkR\n",
    "\n",
    "The following code snippet loads in the data from dashDB directly as a SparkR dataframe.\n",
    "\n",
    "### Why SparkR?\n",
    "Even if your data is stored on dashDB in a relational database, you can now leverage SparkR to access, manipulate and analyze that data. SparkR allows you to work with extremely large datasets. Using SparkR, you can manipulate your data via SQL queries, or via SparkR's native commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext <- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myurl <- paste0(\"jdbc:db2://\",dsn_hostname,\":\", dsn_port,\n",
    "                \"/\", dsn_database,\n",
    "                \":user=\", dsn_username,\n",
    "                \";password=\", dsn_password,\n",
    "                \";\")\n",
    "print(myurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df <- read.df(sqlContext, source=\"jdbc\", \n",
    "             url=myurl,\n",
    "             dbtable=\"GOSALESDW.EMP_EXPENSE_FACT\")\n",
    "\n",
    "class(df) #Confirm that df is a Spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Schema of the Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printSchema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Data\n",
    "You can now use either SQL, or native Spark dataframe functions to query the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "registerTempTable(df, \"tempdf\")\n",
    "\n",
    "results <- sql(sqlContext, \"SELECT * FROM tempdf Limit 10\")\n",
    "\n",
    "# results is now a DataFrame\n",
    "head(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SparkR::head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [Spark course available free on Big Data University](http://bigdatauniversity.com/courses/spark-fundamentals/?utm_source=Data%20Scientist%20Workbench&utm_medium=Notebook&utm_campaign=Tutorial%20-%20Access%20dashDB%20data%20with%20SparkR)\n",
    "- [SparkR Programming Guide](https://spark.apache.org/docs/latest/sparkr.html)\n",
    "\n",
    "### Need a refresher on Apache Spark? \n",
    "Free 3 hr course for beginners on Big Data University:  \n",
    "\n",
    "<a href=http://bigdatauniversity.com/courses/spark-fundamentals/?utm_source=sparkfundamentalsI&utm_medium=dswb&utm_campaign=bdu><img src=https://ibm.box.com/shared/static/r3pj5oo2ivnzqar0poj2eexiqrnvq6vy.png></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Authors:</h3>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "<h4>Saeed Aghabozorgi</h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "</article>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone size-medium wp-image-2177\" src=\"https://ibm.box.com/shared/static/2ygdi03ahcr97df2ofrr6cf8knq4kodd.jpg\" alt=\"Polong Lin\" width=\"300\" height=\"300\" /></div>\n",
    "<h4>Polong Lin</h4>\n",
    "<p>\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">Polong Lin</a> is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds a M.Sc. in Cognitive Psychology.</p>\n",
    "</article>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
