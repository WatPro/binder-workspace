{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo1: Flight Delay Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use the popular [Flights Dataset](http://stat-computing.org/dataexpo/2009/the-data.html) to analyze and predict flight delays in airports based on past flight records. We show how you can use __Jupyter Notebook and Local Spark__ to read, explore, analyze and visualize your results. \n",
    "\n",
    "For this dataset, we will only look at the flights in 2007 - this is still 7 million flights! \n",
    "\n",
    "In this notebook, we will build **a classification model to predict airline delay from historical flight data.**  \n",
    "\n",
    "First, we import some Python packages that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "To import data into your Data Scientist Workbench (DSWB), you can take either one of these actions:\n",
    "\n",
    "1) Paste the following link into the sidebar of your DSWB:\n",
    "https://share.datascientistworkbench.com/#/api/v1/workbench/10.115.89.160/shares/QBNwgXam7veFKl7/airline2007.csv\n",
    "\n",
    "OR\n",
    "\n",
    "2) Run the following cell to download it directly to you DSWB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Will download airline2007.csv if file not yet downloaded\n",
    "\n",
    "if os.path.isfile(\"/resources/airline2007.csv\") != True:\n",
    "    #If file does not already exist, download it, unzip, then delete zipped file\n",
    "    !wget --quiet --output-document  /resources/airline2007.csv.bz2 http://stat-computing.org/dataexpo/2009/2007.csv.bz2\n",
    "    !bzip2 -d /resources/airline2007.csv.bz2\n",
    "    !rm /resources/airline2007.csv.bz2\n",
    "    print \"Downloaded to /resources/airline2007.csv\"\n",
    "else:\n",
    "    #If file already exists\n",
    "    print \"airline2007.csv already exists under /resources/airline2007.csv\"\n",
    "    print \"You can continue to the next cell.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textFile = sc.textFile('/resources/airline2007.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data\n",
    "In this section, we remove the header of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textFileRDD = textFile.map(lambda x: x.split(','))\n",
    "header = textFileRDD.first()\n",
    "\n",
    "textRDD = textFileRDD.filter(lambda r: r != header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataframe from RDD\n",
    "A DataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in Python, but with richer optimizations under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(r):\n",
    "    try:\n",
    "        x=Row(Year=int(r[0]),\\\n",
    "          Month=int(r[1]),\\\n",
    "          DayofMonth=int(r[2]),\\\n",
    "          DayOfWeek=int(r[3]),\\\n",
    "          DepTime=int(float(r[4])), \\\n",
    "          CRSDepTime=int(r[5]),\\\n",
    "          ArrTime=int(float(r[6])),\\\n",
    "          CRSArrTime=int(r[7]), \\\n",
    "          UniqueCarrier=r[8],\\\n",
    "          DepDelay=int(float(r[15])),\\\n",
    "          Origin=r[16],\\\n",
    "          Dest=r[17], \\\n",
    "          Distance=int(float(r[18])))  \n",
    "    except:\n",
    "        x=None  \n",
    "    return x\n",
    "\n",
    "rowRDD = textRDD.map(lambda r: parse(r)).filter(lambda r:r != None)\n",
    "sqlContext = SQLContext(sc)\n",
    "airline_df = sqlContext.createDataFrame(rowRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we add a new column to our data frame, **DepDelayed**, a binary variable:\n",
    "- **True**, for flights that have > 15 minutes of delay\n",
    "- **False**, for flights that have <= 15 minutes of delay\n",
    "\n",
    "We will later use **Depdelayed** as the target/label column in the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airline_df = airline_df.withColumn('DepDelayed', airline_df['DepDelay']>15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a new column, __Hour__, to determine the hour of flight (0 to 24)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -f ./metastore_db/*.lck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define hour function to obtain hour of day\n",
    "def hour_ex(x): \n",
    "    h = int(str(int(x)).zfill(4)[:2])\n",
    "    return h\n",
    "\n",
    "# register as a UDF \n",
    "sqlContext.udf.register(\"hour_ex_py\",hour_ex, IntegerType())\n",
    "f_udf = udf(hour_ex, IntegerType())\n",
    "\n",
    "#CRSDepTime: scheduled departure time (local, hhmm)\n",
    "airline_df = airline_df.withColumn('hour', f_udf(airline_df.CRSDepTime))\n",
    "airline_df.registerTempTable(\"airlineDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "Let's do some exploration of this dataset.  \n",
    "### Exploration: Which Airports have the Most Delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groupedDelay = sqlContext.sql(\"SELECT Origin, count(*) conFlight,avg(DepDelay) delay \\\n",
    "                                FROM airlineDF \\\n",
    "                                GROUP BY Origin\")\n",
    "\n",
    "df_origin = groupedDelay.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notice:__ To map each Airport to corresponding _Long_ and _Lat_, run the following cell to download the needed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Will download airports.dat if not found in /resources/\n",
    "\n",
    "if os.path.isfile(\"/resources/data/airports.dat\") != True:\n",
    "    #If file does not already exist, download it\n",
    "    !wget  --quiet --output-document /resources/data/airports.csv https://ibm.box.com/shared/static/7ou3682c93cpm2gjtu7o0tnijk17jt05.csv\n",
    "    print \"Downloaded to /resources/data/airports.csv\"\n",
    "else:\n",
    "    #If file already exists\n",
    "    print \"airports.dat already exists under /resources/data/airports.csv\"\n",
    "    print \"You can continue to the next cell.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/resources/data/airports.csv', index_col=0,\\\n",
    "names = ['name', 'city', 'country','IATA','ICAO','lat','lng','alt','TZone','DST','Tz','airport','OurAirports'], \\\n",
    "            header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_airports = pd.merge(df_origin, df, left_on = 'Origin', right_on = 'IATA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def zscore(x):\n",
    "    return (x-np.average(x))/np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams['figure.figsize'] = (14,10)\n",
    "\n",
    "\n",
    "my_map = Basemap(projection='merc',\n",
    "            resolution = 'l', area_thresh = 1000.0,\n",
    "            llcrnrlon=-130, llcrnrlat=22, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "            urcrnrlon=-60, urcrnrlat=50) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n",
    "\n",
    "my_map.drawcoastlines()\n",
    "my_map.drawcountries()\n",
    "my_map.drawmapboundary()\n",
    "my_map.fillcontinents(color = 'white', alpha = 0.3)\n",
    "my_map.shadedrelief()\n",
    "\n",
    "# To create a color map\n",
    "colors = plt.get_cmap('hot')(np.linspace(0.0, 1.0, 30))\n",
    "colors=np.flipud(colors)\n",
    "\n",
    "#----- Scatter -------\n",
    "countrange=max(df_airports['conFlight'])-min(df_airports['conFlight'])\n",
    "al=np.array([sigmoid(x) for x in zscore(df_airports['delay'])])\n",
    "xs,ys = my_map(np.asarray(df_airports['lng']), np.asarray(df_airports['lat']))\n",
    "val=df_airports['conFlight']*4000.0/countrange\n",
    "\n",
    "my_map.scatter(xs, ys,  marker='o', s= val, alpha = 0.8,color=colors[(al*20).astype(int)])\n",
    "\n",
    "#----- Text -------\n",
    "df_text=df_airports[(df_airports['conFlight']>60000) & (df_airports['IATA'] != 'HNL')]\n",
    "xt,yt = my_map(np.asarray(df_text['lng']), np.asarray(df_text['lat']))\n",
    "txt=np.asarray(df_text['IATA'])\n",
    "zp=zip(xt,yt,txt)\n",
    "for row in zp:\n",
    "    #print zp[2]\n",
    "    plt.text(row[0],row[1],row[2], fontsize=10, color='blue',)\n",
    "\n",
    "print(\"Each marker is an airport.\")\n",
    "print(\"Size of markers: Airport Traffic (larger means higher number of flights in year)\")\n",
    "print(\"Color of markers: Average Flight Delay (Redder means longer delays)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exploration: Route delay\n",
    "\n",
    "#### Which Routes are typically the most delayed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp_rout_Delay = sqlContext.sql(\"SELECT Origin, Dest, count(*) traffic,avg(Distance) avgDist,\\\n",
    "                                    avg(DepDelay) avgDelay\\\n",
    "                                FROM airlineDF \\\n",
    "                                GROUP BY Origin,Dest\")\n",
    "rout_Delay = grp_rout_Delay.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_airport_rout1 = pd.merge(rout_Delay, df, left_on = 'Origin', right_on = 'IATA')\n",
    "df_airport_rout2 = pd.merge(df_airport_rout1, df, left_on = 'Dest', right_on = 'IATA')\n",
    "df_airport_rout = df_airport_rout2[[\"Origin\",\"lat_x\",\"lng_x\",\"Dest\",\"lat_y\",\"lng_y\",\\\n",
    "                                    \"avgDelay\", \"traffic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (14,10)\n",
    "\n",
    "\n",
    "my_map = Basemap(projection='merc',\n",
    "            resolution = 'l', area_thresh = 1000.0,\n",
    "            llcrnrlon=-130, llcrnrlat=22, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "            urcrnrlon=-60, urcrnrlat=50) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n",
    "\n",
    "my_map.drawcoastlines()\n",
    "my_map.drawcountries()\n",
    "my_map.drawmapboundary()\n",
    "my_map.fillcontinents(color = 'white', alpha = 0.3)\n",
    "my_map.shadedrelief()\n",
    "\n",
    "delay=np.array([sigmoid(x) for x in zscore(df_airports[\"delay\"])])\n",
    "colors = plt.get_cmap('hot')(np.linspace(0.0, 1.0, 40))\n",
    "colors=np.flipud(colors)\n",
    "xs,ys = my_map(np.asarray(df_airports['lng']), np.asarray(df_airports['lat']))\n",
    "xo,yo = my_map(np.asarray(df_airport_rout['lng_x']), np.asarray(df_airport_rout['lat_x']))\n",
    "xd,yd = my_map(np.asarray(df_airport_rout['lng_y']), np.asarray(df_airport_rout['lat_y']))\n",
    "\n",
    "my_map.scatter(xs, ys,  marker='o',  alpha = 0.8,color=colors[(delay*20).astype(int)])\n",
    "\n",
    "\n",
    "al=np.array([sigmoid(x) for x in zscore(df_airport_rout[\"avgDelay\"])])\n",
    "f=zip(xo,yo,xd,yd,df_airport_rout['avgDelay'],al)\n",
    "for row in f:\n",
    "    plt.plot([row[0],row[2]], [row[1],row[3]],'-',alpha=0.07, \\\n",
    "             color=colors[(row[5]*30).astype(int)] )\n",
    "    \n",
    "\n",
    "for row in zp:\n",
    "    plt.text(row[0],row[1],row[2], fontsize=10, color='blue',)\n",
    "\n",
    "print(\"Each line represents a route from the Origin to Destination airport.\")\n",
    "print(\"The redder line, the higher probablity of delay.\")\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration: Airport Origin delay per month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the airport code name below to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Origin_Airport=\"JFK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ORG = sqlContext.sql(\"SELECT * from airlineDF WHERE Origin='\"+ Origin_Airport+\"'\")\n",
    "df_ORG.registerTempTable(\"df_ORG\")\n",
    "df_ORG.select('ArrTime','CRSArrTime','CRSDepTime',\\\n",
    "              'DayOfWeek','DayofMonth','DepDelay','DepTime','Dest').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at flights originating from this airport:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"total flights from this ariport: \" + str(df_ORG.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we group flights by month to see how delayed flights are distributed by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp_carr = sqlContext.sql(\"SELECT  UniqueCarrier,Month, avg(DepDelay) avgDelay from df_ORG \\\n",
    "                            WHERE DepDelayed=True \\\n",
    "                            GROUP BY UniqueCarrier,Month\")\n",
    "s = grp_carr.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = s.pivot(index='Month', columns='UniqueCarrier', values='avgDelay')[['AA','UA','US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (8,5)\n",
    "ps.plot(kind='bar', colormap='Greens');\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average delay')\n",
    "plt.title('How much delay does each carrier has in each month?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that average delay in this year is is highest in June and August in this airport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration: Airport Origin delay per day/hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hour_grouped = df_ORG.filter(df_ORG['DepDelayed']).select('DayOfWeek','hour','DepDelay').groupby('DayOfWeek','hour').mean('DepDelay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (10,5)\n",
    "dh = hour_grouped.toPandas()\n",
    "c = dh.pivot('DayOfWeek','hour')\n",
    "X = c.columns.levels[1].values\n",
    "Y = c.index.values\n",
    "Z = c.values\n",
    "plt.xticks(range(0,24), X)\n",
    "plt.yticks(range(0,7),['Mon','Tue','Wed','Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Day of Week')\n",
    "plt.title('Average delay per hours and day?')\n",
    "plt.imshow(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day of Week: 1 (Monday) - 7 (Sunday) \n",
    "\n",
    "A clear pattern here: flights tend to be delayed in these situations:  \n",
    "- Later in the day (16 to 22): possibly because delays tend to pile up as the day progresses and the problem tends to compound later in the day.  \n",
    "- Mornings in first day of week possibly because of more business meetings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: Logistic Regression\n",
    "In this section, we will build a supervised learning model to predict flight delays for flights leaving our selected airport.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Feature selection\n",
    "In the next two cell we select the features that we need to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_model=df_ORG\n",
    "# stringIndexer1 = StringIndexer(inputCol=\"Origin\", outputCol=\"originIndex\")\n",
    "# model_stringIndexer = stringIndexer1.fit(df_model)\n",
    "# indexedOrigin = model_stringIndexer.transform(df_model)\n",
    "# encoder1 = OneHotEncoder(dropLast=False, inputCol=\"originIndex\", outputCol=\"originVec\")\n",
    "# df_model = encoder1.transform(indexedOrigin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stringIndexer2 = StringIndexer(inputCol=\"Dest\", outputCol=\"destIndex\")\n",
    "model_stringIndexer = stringIndexer2.fit(df_model)\n",
    "indexedDest = model_stringIndexer.transform(df_model)\n",
    "encoder2 = OneHotEncoder(dropLast=False, inputCol=\"destIndex\", outputCol=\"destVec\")\n",
    "df_model = encoder2.transform(indexedDest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use __labeled point__ to make local vectors associated with a label/response. In MLlib, labeled points are used in supervised learning algorithms and they are stored as doubles. For binary classification, a label should be either 0 (negative) or 1 (positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = ['Year','Month','DayofMonth','DayOfWeek','hour','Distance','destVec'],\n",
    "    outputCol = \"features\")\n",
    "output = assembler.transform(df_model)\n",
    "airlineRDD=output.map(lambda row: LabeledPoint([0,1][row['DepDelayed']],row['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Spliting dataset into train and test dtasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainRDD,testRDD=airlineRDD.randomSplit([0.7,0.3])\n",
    "#print str(trainRDD.count()) +\"  \"+ str(testRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(trainRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on testing data\n",
    "labelsAndPreds = testRDD.map(lambda p: (p.label, model.predict(p.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conf(r):\n",
    "    if r[0] == r[1] ==1: x= 'TP'\n",
    "    if r[0] == r[1] ==0: x= 'TN'\n",
    "    if r[0] == 1 and  r[1] ==0: x= 'FN'\n",
    "    if r[0] == 0 and  r[1] ==1: x= 'FP'\n",
    "    return (x)\n",
    "acc1 = labelsAndPreds.map(lambda (v, p): ((v, p),1)).reduceByKey(lambda a, b: a + b).take(5)\n",
    "acc = [(conf(x[0]),x[1]) for x in acc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP=TN=FP=FN=0.0\n",
    "for x in acc: \n",
    "    if x[0]=='TP': TP= x[1]\n",
    "    if x[0]=='TN': TN= x[1]\n",
    "    if x[0]=='FP': FP= x[1]\n",
    "    if x[0]=='FN': FN= x[1]\n",
    "eps = sys.float_info.epsilon\n",
    "Accuracy = (TP+TN) / (TP + TN+ FP+FN+eps) \n",
    "print \"Model Accuracy for JFK: %1.2f %%\" % (Accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to predict your flight from JFK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following widget to query the model.  \n",
    "For example the following flight has dely:  \n",
    "    Month=2, Day=3, Hour=18, Dest=CLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Destin = rout_Delay[rout_Delay['Origin']=='JFK'].Dest.unique()\n",
    "\n",
    "@interact(Destination=tuple(Destin),Month=(1,12),DayOfWeek=(0,7),Hour=(0,23))\n",
    "def g(Destination,Month,DayOfWeek,Hour):\n",
    "    Distance=int(rout_Delay[(rout_Delay['Origin']=='JFK') & (rout_Delay['Dest']==Destination)]\\\n",
    "                 .avgDist.tolist()[0])\n",
    "    testcase=Row(Year=2007.0,Month=Month,DayofMonth=2.0,DayOfWeek=DayOfWeek,hour=Hour,\\\n",
    "                 Origin='JFK',\\\n",
    "          Dest=Destination,Distance=Distance) \n",
    "    TestCase_df = sqlContext.createDataFrame(sc.parallelize([testcase]))\n",
    "    t1= model_stringIndexer.transform(TestCase_df)\n",
    "    t2=encoder2.transform(t1)\n",
    "    p=model.predict(assembler.transform(t2).take(1)[0]['features'])\n",
    "    print \"Flight from JFK to \"+Destination + \", Distance:\" + str(Distance)\n",
    "    if p==0:\n",
    "        print \"You flight doesnt have a delay, Accuracy= %1.2f %%\" % (Accuracy*100)\n",
    "    else:\n",
    "        print \"You flight may be delayed, Accuracy= %1.2f %%\" % (Accuracy*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://bigdatauniversity.com/courses/what-is-spark/?utm_source=tutorial-flight-delay-demo&utm_medium=dswb&utm_campaign=bdu\"><img src = \"https://ibm.box.com/shared/static/r3pj5oo2ivnzqar0poj2eexiqrnvq6vy.png\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Authors:</h3>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "<h4>Saeed Aghabozorgi</h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "</article>\n",
    "<article class=\"teacher\">\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone size-medium wp-image-2177\" src=\"https://ibm.box.com/shared/static/2ygdi03ahcr97df2ofrr6cf8knq4kodd.jpg\" alt=\"Polong Lin\" width=\"300\" height=\"300\" /></div>\n",
    "<h4>Polong Lin</h4>\n",
    "<p>\n",
    "<a href=\"https://ca.linkedin.com/in/polonglin\">Polong Lin</a> is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds a M.Sc. in Cognitive Psychology.</p>\n",
    "</article>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "40049318e6c94538bbab672c917024a3": {
     "views": []
    },
    "4e73a79f3e544acbacf4653c57ce1c14": {
     "views": []
    },
    "6432c95fea304545867a11f803b09b1a": {
     "views": []
    },
    "6d03560741fe46768ad429bb104bd332": {
     "views": []
    },
    "90178561879d4f1db9e5805a1bf3333b": {
     "views": []
    },
    "993c8d8b5ca241bf93b5b77e6fafa414": {
     "views": []
    },
    "a6200edf17624e3eabc9c5872a565141": {
     "views": []
    },
    "b5d7f94dde1d4de0b501aa9128e5b324": {
     "views": []
    },
    "c56be57882534136a5460610a6d8af09": {
     "views": [
      {
       "cell_index": 61
      }
     ]
    },
    "d8ef1b18b969456686d22bbf62fb67c0": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
